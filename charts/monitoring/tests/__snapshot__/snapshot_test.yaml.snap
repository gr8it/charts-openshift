rendered cluster-policy-cluster-monitoring manifest:
  1: |
    apiVersion: kyverno.io/v1
    kind: ClusterPolicy
    metadata:
      labels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: monitoring
        helm.sh/chart: monitoring-1.0.6
      name: cluster-policy-cluster-monitoring
    spec:
      generateExisting: true
      rules:
        - exclude:
            any:
              - resources:
                  kinds:
                    - Namespace
                  names:
                    - openshift*
                    - kube*
                    - default
          generate:
            apiVersion: monitoring.coreos.com/v1
            data:
              spec:
                groups:
                  - name: cluster-monitoring-{{request.object.metadata.name}}
                    rules:
                      - alert: KubePodCrashLooping
                        annotations:
                          description: Pod \{{ $labels.pod }}, container \{{ $labels.container }} in namespace \{{ $labels.namespace }} is in a CrashLoopBackOff state.
                          summary: Pod is crash looping.
                        expr: max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}[5m]) >= 1
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubePodNotReady
                        annotations:
                          description: Pod \{{ $labels.pod }} in namespace \{{ $labels.namespace }} has been in a non-ready state for longer than 15 minutes.
                          summary: Pod has been in a non-ready state for more than 15 minutes.
                        expr: |-
                          sum by (namespace, pod, cluster) (
                            max by (namespace, pod, cluster) (
                              kube_pod_status_phase{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}", phase=~"Pending|Unknown|Failed"}
                            ) * on (namespace, pod, cluster) group_left(owner_kind) topk by (namespace, pod, cluster) (
                              1, max by (namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
                            )
                          ) > 0
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeDeploymentGenerationMismatch
                        annotations:
                          description: Deployment generation for \{{ $labels.deployment }} in namespace \{{ $labels.namespace }} does not match, this indicates that the Deployment has failed but has not been rolled back."
                          summary: Deployment generation mismatch due to possible roll-back
                        expr: |-
                          kube_deployment_status_observed_generation{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            !=
                          kube_deployment_metadata_generation{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeDeploymentReplicasMismatch
                        annotations:
                          description: Deployment \{{ $labels.deployment }} in namespace \{{ $labels.namespace }} has not matched the expected number of replicas for longer than 15 minutes.
                          summary: Deployment has not matched the expected number of replicas.
                        expr: |-
                          (
                            kube_deployment_spec_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                              >
                            kube_deployment_status_replicas_available{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                          ) and (
                            changes(kube_deployment_status_replicas_updated{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}[10m])
                              ==
                            0
                          )
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeDeploymentRolloutStuck
                        annotations:
                          description: Rollout of deployment \{{ $labels.deployment }} in namespace \{{ $labels.namespace }} is not progressing for longer than 15 minutes.
                          summary: Deployment rollout is not progressing.
                        expr: |-
                          kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                          != 0
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeStatefulSetReplicasMismatch
                        annotations:
                          description: StatefulSet \{{ $labels.statefulset }} in namespace \{{ $labels.namespace }} has not matched the expected number of replicas for longer than 15 minutes.
                          summary: StatefulSet has not matched the expected number of replicas.
                        expr: |-
                          (
                            kube_statefulset_status_replicas_ready{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                              !=
                            kube_statefulset_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                          ) and (
                            changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}[10m])
                              ==
                            0
                          )
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeStatefulSetGenerationMismatch
                        annotations:
                          description: StatefulSet generation for \{{ $labels.statefulset }} in namespace \{{ $labels.namespace }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
                          summary: StatefulSet generation mismatch due to possible roll-back
                        expr: |-
                          kube_statefulset_status_observed_generation{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            !=
                          kube_statefulset_metadata_generation{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeStatefulSetUpdateNotRolledOut
                        annotations:
                          description: StatefulSet \{{ $labels.statefulset }} in namespace \{{ $labels.namespace }} update has not been rolled out.
                          summary: StatefulSet update has not been rolled out.
                        expr: |-
                          (
                            max by (namespace, statefulset, job, cluster) (
                              kube_statefulset_status_current_revision{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                                unless
                              kube_statefulset_status_update_revision{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            )
                              * on (namespace, statefulset, job, cluster)
                            (
                              kube_statefulset_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                                !=
                              kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            )
                          )  and on (namespace, statefulset, job, cluster) (
                            changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}[5m])
                              ==
                            0
                          )
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeDaemonSetRolloutStuck
                        annotations:
                          description: DaemonSet \{{ $labels.daemonset }} in namespace \{{ $labels.namespace }} has not finished or progressed for at least 15m.
                          summary: DaemonSet rollout is stuck.
                        expr: |-
                          (
                            (
                              kube_daemonset_status_current_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                                !=
                              kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            ) or (
                              kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                                !=
                              0
                            ) or (
                              kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                                !=
                              kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            ) or (
                              kube_daemonset_status_number_available{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                                !=
                              kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            )
                          ) and (
                            changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}[5m])
                              ==
                            0
                          )
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeContainerWaiting
                        annotations:
                          description: Pod \{{ $labels.pod }} in namespace \{{ $labels.namespace }} on container \{{ $labels.container}} has been in waiting state for longer than 1 hour.
                          summary: Pod container waiting longer than 1 hour
                        expr: kube_pod_container_status_waiting_reason{reason!="CrashLoopBackOff", job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"} > 0
                        for: 1h
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeDaemonSetNotScheduled
                        annotations:
                          description: There are \{{ $value }} pods of DaemonSet \{{ $labels.daemonset }} that are not scheduled.
                          summary: DaemonSet pods are not scheduled.
                        expr: |-
                          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            -
                          kube_daemonset_status_current_number_scheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"} > 0
                        for: 10m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeDaemonSetMisScheduled
                        annotations:
                          description: Found \{{ $value }} mis-scheduled pods for DaemonSet \{{ $labels.daemonset }} in namespace \{{ $labels.namespace }}.
                          summary: DaemonSet pods are misscheduled.
                        expr: kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"} > 0
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeJobNotCompleted
                        annotations:
                          description: Job \{{ $labels.job_name }} in namespace \{{ $labels.namespace }} is taking more than \{{ \"43200\" | humanizeDuration }} to complete.
                          summary: Job did not complete in time
                        expr: |-
                          time() - max by (namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            and
                          kube_job_status_active{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"} > 0) > 43200
                        for: null
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeJobFailed
                        annotations:
                          description: Job \{{ $labels.job_name }} in namespace \{{ $labels.namespace }} failed to complete. Removing failed job after investigation should clear this alert.
                          summary: Job failed to complete.
                        expr: kube_job_failed{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}  > 0
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeHpaReplicasMismatch
                        annotations:
                          description: HPA \{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.
                          summary: HPA has not matched desired number of replicas.
                        expr: |-
                          (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            !=
                          kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"})
                            and
                          (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            >
                          kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"})
                            and
                          (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            <
                          kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"})
                            and
                          changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}[15m]) == 0
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubeHpaMaxedOut
                        annotations:
                          description: HPA \{{ $labels.horizontalpodautoscaler  }} in namespace \{{ $labels.namespace }} has been running at max replicas for longer than 15 minutes.
                          summary: HPA is running at max replicas
                        expr: |-
                          kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            ==
                          kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubePdbNotEnoughHealthyPods
                        annotations:
                          description: PDB \{{ $labels.poddisruptionbudget }} expects \{{ $value }} more healthy pods. The desired number of healthy pods has not been met for at least 15m.
                          summary: PDB does not have enough healthy pods.
                        expr: |-
                          (
                            kube_poddisruptionbudget_status_desired_healthy{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                            -
                            kube_poddisruptionbudget_status_current_healthy{job="kube-state-metrics", namespace="{{ request.object.metadata.name }}"}
                          )
                          > 0
                        for: 15m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubePersistentVolumeFillingUp
                        annotations:
                          description: The PersistentVolume claimed by \{{ $labels.persistentvolumeclaim }} in namespace \{{ $labels.namespace }} is only \{{ $value | humanizePercentage }} free.
                          summary: PersistentVolume is filling up.
                        expr: |-
                          (
                            kubelet_volume_stats_available_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                              /
                            kubelet_volume_stats_capacity_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                          ) < 0.03
                          and
                          kubelet_volume_stats_used_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"} > 0
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                        for: 1m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: critical
                          team: platform
                          vendor: aspecta
                      - alert: KubePersistentVolumeFillingUp
                        annotations:
                          description: Based on recent sampling, the PersistentVolume claimed by \{{ $labels.persistentvolumeclaim }} in namespace \{{ $labels.namespace }} is expected to fill up within four days. Currently \{{ $value | humanizePercentage }} is available.
                          summary: PersistentVolume is filling up.
                        expr: |-
                          (
                            kubelet_volume_stats_available_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                              /
                            kubelet_volume_stats_capacity_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                          ) < 0.15
                          and
                          kubelet_volume_stats_used_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"} > 0
                          and
                          predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                        for: 1h
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubePersistentVolumeInodesFillingUp
                        annotations:
                          description: The PersistentVolume claimed by \{{ $labels.persistentvolumeclaim }} in namespace \{{ $labels.namespace }} has only \{{ $value | humanizePercentage }} free inodes.
                          summary: PersistentVolumeInodes are filling up.
                        expr: |-
                          (
                            kubelet_volume_stats_inodes_free{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                              /
                            kubelet_volume_stats_inodes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                          ) < 0.03
                          and
                          kubelet_volume_stats_inodes_used{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"} > 0
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                        for: 1m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: critical
                          team: platform
                          vendor: aspecta
                      - alert: KubePersistentVolumeInodesFillingUp
                        annotations:
                          description: Based on recent sampling, the PersistentVolume claimed by \{{ $labels.persistentvolumeclaim }} in namespace \{{ $labels.namespace }} is expected to run out of inodes within four days. Currently \{{ $value | humanizePercentage }} of its inodes are free.
                          summary: PersistentVolumeInodes are filling up.
                        expr: |-
                          (
                            kubelet_volume_stats_inodes_free{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                              /
                            kubelet_volume_stats_inodes{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}
                          ) < 0.15
                          and
                          kubelet_volume_stats_inodes_used{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"} > 0
                          and
                          predict_linear(kubelet_volume_stats_inodes_free{job="kubelet", namespace="{{ request.object.metadata.name }}", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
                          unless on (cluster, namespace, persistentvolumeclaim)
                          kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
                        for: 1h
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: warning
                          team: platform
                          vendor: aspecta
                      - alert: KubePersistentVolumeErrors
                        annotations:
                          description: The persistent volume \{{ $labels.persistentvolume }} has status \{{ $labels.phase }}.
                          summary: PersistentVolume is having issues with provisioning.
                        expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
                        for: 5m
                        labels:
                          namespace: '{{request.object.metadata.name}}'
                          severity: critical
                          team: platform
                          vendor: aspecta
            kind: PrometheusRule
            name: cluster-monitoring-{{request.object.metadata.name}}
            namespace: '{{request.object.metadata.name}}'
            synchronize: true
          match:
            any:
              - resources:
                  kinds:
                    - Namespace
          name: generate-prometheus-rules-labels
          preconditions:
            all:
              - key: '{{request.object.metadata.labels."openshift.io/cluster-monitoring" || ''''}}'
                operator: In
                value:
                  - "true"
          skipBackgroundRequests: true
